{"nbformat_minor": 2, "cells": [{"source": "# Lab 4 - Sentiment Analysis for Yelp Reviews\n\nIn Lab 2, we looked at how Spark SQL could help us develop useful features for merging and processing our data in HDFS. In Lab 3, we trained a few regression algorithms using Spark ML pipelines and used cross-validation for hyperparameter tuning. The focus of this lab is natural language processing with Spark ML, with the downstream goal of creating sentiment classifiers on the reviews data.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "%%configure\n{ \"name\":\"SparkSQL_Lab\", \n  \"executorMemory\": \"8G\", \n  \"executorCores\": 2, \n  \"numExecutors\": 20, \n  \"driverCores\": 2\n}", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Reading Data from a Different Storage Container\n\nBy default, all storage containers have access to each other within a storage account. In contract, for ADLS, you have to specify the ACLs at the directory level for each cluster. In the chunk below, we'll create two variables containing our container name and the storage account name, and concatenate those strings together to create a path for our data directory in our storage container. ", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "var container = \"wasb://azmaybach-2017-08-28\"\nvar storageaccount = \"@azaidihdi.blob.core.windows.net/yelp/data/\"\n\nvar full_url = container.concat(storageaccount)\nprintln(full_url)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "var biz_path = full_url.concat(\"yelp_academic_dataset_business.json\")\nvar reviews_path = full_url.concat(\"yelp_academic_dataset_review.json\")\n\nval business = spark.read.json(biz_path)\nval reviews = spark.read.json(reviews_path)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "println(\"Number of records in reviews table: \" + reviews.count())", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "println(\"Number of records in businesses table: \" + business.count())", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "business.printSchema()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "business.show(1)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "val biz_names = Seq(\"business_id\", \"name\", \"city\", \"stars\", \"state\",\n                    \"categories\", \"attributes\", \"address\", \"review_count\")\nval biz = business.select(biz_names.map(c => col(c)): _*)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "biz.show()", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "val biz_star = business.withColumnRenamed(\"stars\", \"ave_stars\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "biz_star.createOrReplaceTempView(\"business\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nselect * from business limit 10", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "reviews.cache()\nbiz_star.cache()", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Merge the Datasets\n\nAs we described in Lab 2, we will merge in the two tables to create a final table we will use for modeling.", "cell_type": "markdown", "metadata": {}}, {"execution_count": null, "cell_type": "code", "source": "val biz_reviews = biz_star.join(reviews, \n                                biz_star.col(\"business_id\") === reviews.col(\"business_id\"), \n                                \"left_outer\")", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "biz_reviews.explain(true)", "outputs": [], "metadata": {"collapsed": false}}, {"execution_count": null, "cell_type": "code", "source": "biz_reviews.cache()\nbiz_reviews.createOrReplaceTempView(\"joinedReviews\")", "outputs": [], "metadata": {"collapsed": true}}, {"execution_count": null, "cell_type": "code", "source": "%%sql\nselect * from joinedReviews limit 10", "outputs": [], "metadata": {"collapsed": false}}, {"source": "## Tokenizing Text\n\nTokenization is the process of converting text data into an vector of \"tokens\" of individual components, usually words.", "cell_type": "markdown", "metadata": {}}, {"source": "### Exercise 1: Tokenize the reviews data\n\n1. Use the [Tokenizer](https://spark.apache.org/docs/latest/ml-features.html#tokenizer) class to convert the reviews column into an array of tokens\n    - [Tokenizer docs](https://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.ml.feature.Tokenizer)\n2. Use the [StopWordsRemover](https://spark.apache.org/docs/latest/ml-features.html#stopwordsremover) to remove stop words from your tokens array", "cell_type": "markdown", "metadata": {}}, {"source": "## Exercise 2\n\nBuild a SparkML Pipeline for training a sentiment classifier. You'll use the tokenizer you created earlier and the add pipeline stages for additional feature variables and the estimator for the classifier module. Split your data into train and test splits and then calculate your classifier's AUC.\n\nUseful modules:\n* `org.apache.spark.ml.feature.{VectorAssembler, HashingTF, IDF, Tokenizer, Binarizer}`\n* `import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics`", "cell_type": "markdown", "metadata": {}}, {"source": "## Pipeline", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Spark", "name": "sparkkernel", "language": ""}, "language_info": {"mimetype": "text/x-scala", "pygments_lexer": "scala", "name": "scala", "codemirror_mode": "text/x-scala"}}}